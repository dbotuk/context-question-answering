{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ada395b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-09-30T08:27:24.527572Z",
     "start_time": "2024-09-30T08:27:20.009659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.41.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (4.41.1)\r\n",
      "Requirement already satisfied: datasets in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (2.12.0)\r\n",
      "Requirement already satisfied: torch==2.1.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: mlflow==2.13.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (2.13.1)\r\n",
      "Requirement already satisfied: boto3==1.34.122 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (1.34.122)\r\n",
      "Requirement already satisfied: filelock in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (3.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (0.25.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (2022.7.9)\r\n",
      "Requirement already satisfied: requests in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (0.4.5)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from transformers==4.41.1) (4.65.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch==2.1.0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch==2.1.0) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch==2.1.0) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch==2.1.0) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from torch==2.1.0) (2024.9.0)\r\n",
      "Requirement already satisfied: Flask<4 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (2.2.2)\r\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (1.13.1)\r\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (5.3.2)\r\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (8.0.4)\r\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (2.2.1)\r\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (7.1.0)\r\n",
      "Requirement already satisfied: entrypoints<1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (0.4)\r\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (3.1.43)\r\n",
      "Requirement already satisfied: graphene<4 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (3.3)\r\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (6.0.0)\r\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (3.4.1)\r\n",
      "Requirement already satisfied: matplotlib<4 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (3.7.2)\r\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (1.27.0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (1.27.0)\r\n",
      "Requirement already satisfied: pandas<3 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (2.1.1)\r\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (4.23.4)\r\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (13.0.0)\r\n",
      "Requirement already satisfied: pytz<2025 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: querystring-parser<2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (1.2.4)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (1.3.0)\r\n",
      "Requirement already satisfied: scipy<2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (1.11.1)\r\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (2.0.21)\r\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (0.5.1)\r\n",
      "Requirement already satisfied: gunicorn<23 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.1) (22.0.0)\r\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.122 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from boto3==1.34.122) (1.34.162)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from boto3==1.34.122) (0.10.0)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from boto3==1.34.122) (0.10.2)\r\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: xxhash in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: multiprocess in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: aiohttp in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\r\n",
      "Requirement already satisfied: responses<0.19 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\r\n",
      "Requirement already satisfied: Mako in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.1) (1.3.5)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.122->boto3==1.34.122) (2.8.2)\r\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.122->boto3==1.34.122) (1.26.16)\r\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow==2.13.1) (2.2.3)\r\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow==2.13.1) (2.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow==2.13.1) (4.0.11)\r\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow==2.13.1) (3.2.4)\r\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow==2.13.1) (3.2.0)\r\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow==2.13.1) (9.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.13.1) (3.11.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.1.0) (2.1.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.1) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.1) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.1) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.1) (1.4.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.1) (9.4.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.1) (3.0.9)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow==2.13.1) (1.2.14)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow==2.13.1) (0.48b0)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from pandas<3->mlflow==2.13.1) (2023.3)\r\n",
      "Requirement already satisfied: six in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from querystring-parser<2->mlflow==2.13.1) (1.16.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.41.1) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from requests->transformers==4.41.1) (2023.7.22)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow==2.13.1) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow==2.13.1) (2.2.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.1.0) (1.3.0)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow==2.13.1) (1.14.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/denisbotuk/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.13.1) (5.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.41.1 datasets torch==2.1.0 mlflow==2.13.1 boto3==1.34.122 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17f296f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:27:27.567206Z",
     "start_time": "2024-09-30T08:27:24.528973Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models import infer_signature\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from src.utils import load_squad_data, SquadDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68083e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:27:27.570030Z",
     "start_time": "2024-09-30T08:27:27.567822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set model training parameters\n",
    "params = {\n",
    "    'learning_rate': 5e-5,\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 3,\n",
    "    'max_len': 512,\n",
    "    'no_answer_threshold': 0.5,\n",
    "    'tokenizer': \"distilbert-base-uncased\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed264ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:27:28.239222Z",
     "start_time": "2024-09-30T08:27:27.571470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DistilBertForQuestionAnswering(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set environment variables for MLflow and Minio (object storage)\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"miniopass\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\" \n",
    " \n",
    "mlflow_tracking_url = \"http://localhost:3000\"\n",
    "model_artifact_name = \"bert_model\"\n",
    "experiment_name = \"bert-baseline\"\n",
    "\n",
    "# Set up MLflow experiment tracking\n",
    "mlflow.set_tracking_uri(mlflow_tracking_url)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Select device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(params['tokenizer'])\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac2cfe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:27:28.795144Z",
     "start_time": "2024-09-30T08:27:28.240111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load SQuAD training and validation datasets\n",
    "train_data = load_squad_data('../data/train-v2.0.json')\n",
    "dev_data = load_squad_data('../data/dev-v2.0.json')\n",
    "\n",
    "# Create PyTorch Datasets\n",
    "train_dataset = SquadDataset(train_data, tokenizer, params['max_len'])\n",
    "dev_dataset = SquadDataset(dev_data, tokenizer, params['max_len'])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1234f13b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T17:15:23.986061Z",
     "start_time": "2024-09-30T08:27:28.795907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1424 [00:33<3:25:21,  8.68s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  8%|▊         | 121/1424 [14:50<2:35:47,  7.17s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 16%|█▌        | 221/1424 [26:51<2:21:54,  7.08s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 18%|█▊        | 256/1424 [31:07<2:39:05,  8.17s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 21%|██        | 299/1424 [36:43<2:29:15,  7.96s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 28%|██▊       | 405/1424 [50:14<2:02:36,  7.22s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 34%|███▍      | 487/1424 [1:00:14<1:56:40,  7.47s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 36%|███▋      | 518/1424 [1:04:16<1:58:33,  7.85s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 38%|███▊      | 538/1424 [1:06:56<1:59:13,  8.07s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 56%|█████▋    | 801/1424 [1:38:57<1:12:46,  7.01s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 68%|██████▊   | 973/1424 [2:00:48<47:29,  6.32s/it]  Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 75%|███████▌  | 1070/1424 [2:12:28<40:10,  6.81s/it] Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 76%|███████▋  | 1088/1424 [2:14:24<35:19,  6.31s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 87%|████████▋ | 1232/1424 [2:29:56<20:33,  6.42s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 95%|█████████▌| 1353/1424 [2:44:32<08:32,  7.22s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.4732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1424 [00:36<2:49:50,  7.18s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  3%|▎         | 42/1424 [05:13<2:50:33,  7.40s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  4%|▍         | 58/1424 [07:10<2:42:28,  7.14s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  9%|▉         | 135/1424 [16:23<2:32:36,  7.10s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 27%|██▋       | 391/1424 [48:35<2:28:22,  8.62s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 29%|██▊       | 409/1424 [51:02<2:22:21,  8.42s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 43%|████▎     | 616/1424 [1:16:27<1:29:16,  6.63s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 44%|████▍     | 626/1424 [1:17:39<1:39:19,  7.47s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 44%|████▍     | 631/1424 [1:18:14<1:32:27,  7.00s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 46%|████▌     | 656/1424 [1:21:19<1:32:02,  7.19s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 77%|███████▋  | 1093/1424 [2:12:49<41:28,  7.52s/it] Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 84%|████████▍ | 1200/1424 [2:24:50<25:04,  6.72s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 86%|████████▌ | 1220/1424 [2:26:58<21:16,  6.26s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 90%|█████████ | 1288/1424 [2:34:19<15:33,  6.86s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 94%|█████████▍| 1341/1424 [2:39:58<08:56,  6.46s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 4.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 56/1424 [06:02<2:38:48,  6.97s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  8%|▊         | 108/1424 [12:05<2:27:18,  6.72s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  9%|▉         | 125/1424 [13:57<2:15:36,  6.26s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 35%|███▍      | 496/1424 [58:40<1:53:40,  7.35s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 39%|███▉      | 559/1424 [1:06:27<1:53:07,  7.85s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 41%|████▏     | 588/1424 [1:10:10<1:47:22,  7.71s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 42%|████▏     | 591/1424 [1:10:33<1:48:35,  7.82s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 55%|█████▍    | 782/1424 [1:34:43<1:20:55,  7.56s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 58%|█████▊    | 825/1424 [1:40:10<1:13:06,  7.32s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 62%|██████▏   | 881/1424 [1:47:12<1:08:48,  7.60s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 65%|██████▍   | 919/1424 [1:51:56<1:00:42,  7.21s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 65%|██████▌   | 931/1424 [1:53:29<1:04:26,  7.84s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 78%|███████▊  | 1106/1424 [2:15:40<41:03,  7.75s/it] Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 79%|███████▉  | 1128/1424 [2:18:25<37:26,  7.59s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "100%|█████████▉| 1422/1424 [2:55:42<00:14,  7.36s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "/var/folders/tg/jlvzghzj7px6zbtkv9swtpg40000gn/T/ipykernel_9301/2115840020.py:45: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 4.1472\n",
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 99/371 [02:20<06:43,  1.48s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 27%|██▋       | 100/371 [02:22<06:44,  1.49s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 27%|██▋       | 101/371 [02:24<06:57,  1.55s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 28%|██▊       | 104/371 [02:28<06:53,  1.55s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 28%|██▊       | 105/371 [02:30<06:50,  1.54s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 29%|██▊       | 106/371 [02:31<06:43,  1.52s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 29%|██▉       | 107/371 [02:33<06:38,  1.51s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 38%|███▊      | 140/371 [03:20<05:30,  1.43s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 43%|████▎     | 159/371 [03:49<05:16,  1.49s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      " 43%|████▎     | 160/371 [03:51<05:15,  1.49s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match (EM): 44.4331983805668\n",
      "F1 Score: 55.98606668633911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 18:15:16 INFO mlflow.types.utils: MLflow 2.9.0 introduces model signature with new data types for lists and dictionaries. For input such as Dict[str, Union[scalars, List, Dict]], we infer dictionary values types as `List -> Array` and `Dict -> Object`. \n",
      "2024/09/30 18:15:16 INFO mlflow.models.utils: We convert input dictionaries to pandas DataFrames such that each key represents a column, collectively constituting a single row of data. If you would like to save data as multiple rows, please convert your data to a pandas DataFrame before passing to input_example.\n",
      "/Users/denisbotuk/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "early_stopping_counter = 0\n",
    "\n",
    "# Start MLflow run for logging experiments and metrics\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    input_ids, attention_mask, outputs = None, None, None\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop for specified epochs\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "    \n",
    "            # Zero out previous gradients\n",
    "            optimizer.zero_grad() \n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs.loss\n",
    "    \n",
    "            # Backward pass (gradient calculation)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Track total loss for the epoch\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Load evaluation metric (SQuAD v2 format)\n",
    "    metric = load_metric(\"squad_v2\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    print(\"Evaluation...\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluation loop\n",
    "    for batch in tqdm(dev_loader, leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "    \n",
    "        # Disable gradient calculation for evaluation\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "    \n",
    "        # Get the predicted start and end positions\n",
    "        start_pred = torch.argmax(start_logits, dim=-1)\n",
    "        end_pred = torch.argmax(end_logits, dim=-1)\n",
    "        \n",
    "        # Calculate max start and end logits for no-answer probability\n",
    "        start_logit_max = torch.max(start_logits, dim=-1).values\n",
    "        end_logit_max = torch.max(end_logits, dim=-1).values\n",
    "    \n",
    "        # Calculate no-answer probability\n",
    "        no_answer_prob = 1 - (start_logit_max + end_logit_max) / 2.0\n",
    "    \n",
    "        # Process batch predictions and references\n",
    "        for i in range(input_ids.size(0)):\n",
    "            # Convert start and end predictions to Python integers\n",
    "            pred_start = start_pred[i].item()\n",
    "            pred_end = end_pred[i].item()\n",
    "    \n",
    "            # Handle no-answer predictions based on threshold\n",
    "            if no_answer_prob[i] > params['no_answer_threshold']:\n",
    "                pred_answer = \"\"  # No answer prediction\n",
    "            else:\n",
    "                # Handle no-answer predictions based on threshold\n",
    "                pred_answer = tokenizer.decode(input_ids[i][pred_start:pred_end + 1], skip_special_tokens=True)\n",
    "    \n",
    "            # Decode ground truth (reference) answer\n",
    "            true_start = start_positions[i].item()\n",
    "            true_end = end_positions[i].item()\n",
    "            true_answer = tokenizer.decode(input_ids[i][true_start:true_end + 1], skip_special_tokens=True)\n",
    "    \n",
    "            # Append prediction with no-answer probability for SQuAD v2 metric\n",
    "            predictions.append({\n",
    "                \"id\": str(batch['id'][i]),\n",
    "                \"prediction_text\": pred_answer,\n",
    "                \"no_answer_probability\": float(no_answer_prob[i].item())\n",
    "            })\n",
    "    \n",
    "            # Append the reference (ground truth) answer\n",
    "            references.append({\n",
    "                \"id\": batch['id'][i],\n",
    "                \"answers\": {\n",
    "                    \"text\": [true_answer],\n",
    "                    \"answer_start\": [true_start]\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Compute evaluation metrics using Huggingface `datasets` metric\n",
    "    metric.add_batch(predictions=predictions, references=references)\n",
    "    final_score = metric.compute()\n",
    "    \n",
    "    print(f\"Exact Match (EM): {final_score['exact']}\")\n",
    "    print(f\"F1 Score: {final_score['f1']}\")\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"em\", final_score['exact'])\n",
    "    mlflow.log_metric(\"f1\", final_score['f1'])\n",
    "    \n",
    "    # Prepare example input for MLflow signature\n",
    "    input_example = {\n",
    "        \"input_ids\": input_ids[0].numpy().tolist(),\n",
    "        \"attention_mask\": attention_mask[0].numpy().tolist()\n",
    "    }\n",
    "    \n",
    "    # Infer input-output signature for logging the model\n",
    "    signature = infer_signature(input_example, outputs[0].detach().numpy())\n",
    "\n",
    "    # Log the trained model to MLflow\n",
    "    mlflow.pytorch.log_model(model, \n",
    "                            artifact_path=model_artifact_name,\n",
    "                            signature=signature,\n",
    "                            input_example=input_example\n",
    "                             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
